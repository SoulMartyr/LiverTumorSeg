{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb2536d9-a53b-4d53-a0a8-122915e5f910",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "from torch.cuda import amp\n",
    "\n",
    "import Config\n",
    "from models.HDenseUNet import AmpHDenseUNet\n",
    "from models.UNet3D import AmpUNet3D\n",
    "from utils.DataFunc import *\n",
    "from utils.Logger import *\n",
    "from utils.LossFunc import *\n",
    "from utils.UtilFunc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f4c560f-a04b-489b-9cc6-546dc11ad4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(test_loader, model):\n",
    "    model.eval()\n",
    "    valid_tot_loss = 0.\n",
    "    valid_tot_dice = 0.\n",
    "    for _, batch in enumerate(test_loader):\n",
    "        ct = batch['ct'].cuda()\n",
    "        seg = batch['seg'].cuda()\n",
    "        with torch.no_grad():\n",
    "            out = model(ct)\n",
    "            valid_loss = weighted_cross_entropy_loss(out, seg)\n",
    "            valid_dice = tumor_dice(out, seg)\n",
    "        valid_tot_loss += valid_loss.item()\n",
    "        valid_tot_dice += valid_dice.item()\n",
    "\n",
    "    return [valid_tot_loss / len(test_loader), valid_tot_dice / len(test_loader)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28efe8a7-64e4-44b3-b733-a92ea21ee40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_weight(weight_dir, iteration, epoch, model_state_dict, optim_state_dict, is_amp, scaler_state_dict):\n",
    "    checkpoint = {\n",
    "        'iteration': iteration,\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model_state_dict,\n",
    "        'optim_state_dict': optim_state_dict\n",
    "    }\n",
    "    if is_amp:\n",
    "        checkpoint['scaler_state_dict'] = scaler_state_dict\n",
    "    torch.save(checkpoint, weight_dir +\n",
    "               '/{}epoch_{}iter.pth'.format(epoch, iteration))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89f51bd3-23d9-4050-b0b8-b3028a704bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(start_epoch, start_iteration, train_loader, test_loader, model, is_amp, optimizer, grad_scaler,\n",
    "          save_epoch, weight_dir, log_iteration):\n",
    "    log_msg_head(epoch_num, batch_size)\n",
    "\n",
    "    best_dice = torch.FloatTensor(0)\n",
    "\n",
    "    epoch = start_epoch\n",
    "    iteration = start_iteration\n",
    "\n",
    "    while epoch < epoch_num:\n",
    "        if epoch != start_epoch:\n",
    "            iteration = 0\n",
    "        model.train()\n",
    "        is_epoch_saved = False\n",
    "        for _, batch in enumerate(train_loader):\n",
    "            if hasattr(torch.cuda, 'empty_cache'):\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "            is_save = False\n",
    "            if not is_epoch_saved and epoch % save_epoch == 0 and epoch != start_epoch:\n",
    "                test_accuracy = test(test_loader, model)\n",
    "                model.train()\n",
    "                if test_accuracy[1] < best_dice:\n",
    "                    save_weight(weight_dir, epoch, iteration, model.state_dict(), optimizer.state_dict(), is_amp,\n",
    "                                grad_scaler.state_dict())\n",
    "                    best_dice = test_accuracy\n",
    "                    is_save = True\n",
    "                is_epoch_saved = True\n",
    "            else:\n",
    "                test_accuracy = [None, None]\n",
    "\n",
    "            ct = batch['ct'].cuda()\n",
    "            seg = batch['seg'].cuda()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            with amp.autocast():\n",
    "                out = model(ct)\n",
    "                train_loss = weighted_cross_entropy_loss(out, seg)\n",
    "                train_dice = tumor_dice(out, seg)\n",
    "                train_accuracy = [train_loss.item(), train_dice.item()]\n",
    "\n",
    "            grad_scaler.scale(train_loss).backward()\n",
    "            grad_scaler.step(optimizer)\n",
    "            grad_scaler.update()\n",
    "\n",
    "            if iteration % log_iteration == 0 and iteration != start_iteration:\n",
    "                lr = get_learning_rate(optimizer)\n",
    "                log_msg(epoch, iteration, lr, train_accuracy,\n",
    "                        test_accuracy, is_save)\n",
    "\n",
    "            iteration += 1\n",
    "\n",
    "        epoch += 1\n",
    "        log_flush()\n",
    "    return best_dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2d82652-66ad-4365-b6b8-4c448fb3d176",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Config.args\n",
    "\n",
    "# device = torch.device('cuda' if args.gpu else 'cpu')\n",
    "\n",
    "# if args.gpu:\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "\n",
    "is_amp = args.amp\n",
    "\n",
    "train_crop_slices = args.train_crop_size\n",
    "test_crop_slices = args.test_crop_size\n",
    "num_classes = args.num_classes\n",
    "\n",
    "model_name = args.model\n",
    "if model_name == \"unet3d\":\n",
    "    model = AmpUNet3D(out_channels=num_classes)\n",
    "            log_file = set_logfile(AmpUNet3D.__name__)\n",
    "elif model_name == \"hdenseunet\":\n",
    "    model = AmpHDenseUNet(\n",
    "    num_slices=train_crop_slices, out_channels=num_classes)\n",
    "    log_file = set_logfile(AmpHDenseUNet.__name__)\n",
    "else:\n",
    "    raise NameError(\"No model named\" + model_name)\n",
    "\n",
    "batch_size = args.batch_size\n",
    "num_workers = args.num_workers\n",
    "learning_rate = args.lr\n",
    "epoch_num = args.epoch_num\n",
    "save_epoch = args.save_epoch\n",
    "log_iteration = args.log_iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66af3f64-d820-4368-8cd1-1cb065c80ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "index_df = pd.read_csv(args.index_path, index_col=0)\n",
    "train_index = index_df.loc[\"train\", \"index\"].strip().split(\" \")\n",
    "test_index = index_df.loc[\"test\", \"index\"].strip().split(\" \")\n",
    "\n",
    "train_data_path = args.train_data_path\n",
    "test_data_path = args.test_data_path\n",
    "\n",
    "train_dataset = TiLSDataSet(data_path=train_data_path, index_list=train_index,\n",
    "                            crop_slices=train_crop_slices, num_classes=num_classes, is_normalize=False)\n",
    "test_dataset = TiLSDataSet(data_path=test_data_path, index_list=test_index,\n",
    "                            crop_slices=test_crop_slices, num_classes=num_classes, is_normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29fa9398-374e-4c29-8d18-4595ebfbdd47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01:01:37 Load DataSet Success\n"
     ]
    }
   ],
   "source": [
    "train_loader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    drop_last=False,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=True\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    drop_last=False,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "log_hint(\"Load DataSet Success\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25b51e52-2c26-4e2b-a413-475657408053",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01:01:44 Load Model And Optimizer Success\n"
     ]
    }
   ],
   "source": [
    "# Load Model\n",
    "grad_scaler = amp.GradScaler()\n",
    "model = TestAmpModel(out_channels=num_classes).cuda()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "checkpoint_path = args.checkpoint_path\n",
    "weight_dir = os.path.join(\n",
    "    checkpoint_path, '{}'.format(model.__class__.__name__))\n",
    "if not os.path.exists(weight_dir):\n",
    "    os.makedirs(weight_dir)\n",
    "\n",
    "weights = os.listdir(weight_dir)\n",
    "weight_path = None\n",
    "\n",
    "if len(weights) != 0:\n",
    "    weights = sorted(weights, key=lambda x: os.path.getmtime(\n",
    "        os.path.join(weight_dir, x)))\n",
    "    weight_path = weights[-1]\n",
    "\n",
    "if weight_path is not None:\n",
    "    weight = torch.load(weight_path)\n",
    "    start_iteration = weight['iteration']\n",
    "    start_epoch = weight['epoch']\n",
    "    model.load_state_dict(weight['model_state_dict'], strict=False)\n",
    "    optimizer.load_state_dict(weight['optim_state_dict'])\n",
    "    if is_amp:\n",
    "        grad_scaler.load_state_dict(weight['scaler_state_dict'])\n",
    "    print(\"start_epoch:\", start_epoch, \"start_iteration:\", start_iteration)\n",
    "else:\n",
    "    start_iteration = 0\n",
    "    start_epoch = 0\n",
    "log_hint(\"Load Model And Optimizer Success\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "741ec566-aed0-4d38-9c87-47786303204f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_num = 20\n",
      "batch_size = 2\n",
      "|---------------Info----------------|------Train------|------Valid------|\n",
      "| time       epoch    iter   lr     | loss     dice   | loss     dice   |\n",
      "-------------------------------------------------------------------------\n",
      "| 01:02:13   0        5      0.001  | 3.6552   -2.162 | None     None   |\n",
      "| 01:02:34   0        10     0.001  | 2.3015   -1.132 | None     None   |\n",
      "| 01:02:54   0        15     0.001  | -0.817   1.7086 | None     None   |\n",
      "| 01:03:15   0        20     0.001  | 1.7766   -0.266 | None     None   |\n",
      "5\n",
      "| 01:03:43   0        25     0.001  | 0.3725   0.5175 | nan      nan    |\n",
      "| 01:04:03   0        30     0.001  | 0.3210   0.7712 | None     None   |\n",
      "| 01:04:24   0        35     0.001  | -0.839   2.8011 | None     None   |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fee5056b0d0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/miniconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/root/miniconda3/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1304, in _shutdown_workers\n",
      "    q.close()\n",
      "  File \"/root/miniconda3/lib/python3.8/multiprocessing/queues.py\", line 142, in close\n",
      "    close()\n",
      "  File \"/root/miniconda3/lib/python3.8/multiprocessing/util.py\", line 224, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/root/miniconda3/lib/python3.8/multiprocessing/queues.py\", line 202, in _finalize_close\n",
      "    debug('telling queue thread to quit')\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_1161/112178049.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;31m# Start Train\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 2\u001B[0;31m \u001B[0mtrain\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mstart_epoch\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mstart_iteration\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtrain_loader\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mvalid_loader\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0moptimizer\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mgrad_scaler\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msave_iteration\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mweight_dir\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlog_iteration\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m/tmp/ipykernel_1161/1978741762.py\u001B[0m in \u001B[0;36mtrain\u001B[0;34m(start_epoch, start_iteration, train_loader, valid_loader, model, optimizer, grad_scaler, save_iteration, weight_dir, log_iteration)\u001B[0m\n\u001B[1;32m     27\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     28\u001B[0m             \u001B[0mgrad_scaler\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mscale\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtrain_loss\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbackward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 29\u001B[0;31m             \u001B[0mgrad_scaler\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstep\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0moptimizer\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     30\u001B[0m             \u001B[0mgrad_scaler\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mupdate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     31\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/lib/python3.8/site-packages/torch/cuda/amp/grad_scaler.py\u001B[0m in \u001B[0;36mstep\u001B[0;34m(self, optimizer, *args, **kwargs)\u001B[0m\n\u001B[1;32m    336\u001B[0m         \u001B[0;32massert\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0moptimizer_state\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"found_inf_per_device\"\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m>\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"No inf checks were recorded for this optimizer.\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    337\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 338\u001B[0;31m         \u001B[0mretval\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_maybe_opt_step\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0moptimizer\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0moptimizer_state\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    339\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    340\u001B[0m         \u001B[0moptimizer_state\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"stage\"\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mOptState\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mSTEPPED\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/lib/python3.8/site-packages/torch/cuda/amp/grad_scaler.py\u001B[0m in \u001B[0;36m_maybe_opt_step\u001B[0;34m(self, optimizer, optimizer_state, *args, **kwargs)\u001B[0m\n\u001B[1;32m    282\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m_maybe_opt_step\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0moptimizer\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0moptimizer_state\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    283\u001B[0m         \u001B[0mretval\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 284\u001B[0;31m         \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0msum\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mv\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mitem\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mv\u001B[0m \u001B[0;32min\u001B[0m \u001B[0moptimizer_state\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"found_inf_per_device\"\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mvalues\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    285\u001B[0m             \u001B[0mretval\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0moptimizer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstep\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    286\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mretval\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniconda3/lib/python3.8/site-packages/torch/cuda/amp/grad_scaler.py\u001B[0m in \u001B[0;36m<genexpr>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m    282\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m_maybe_opt_step\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0moptimizer\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0moptimizer_state\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    283\u001B[0m         \u001B[0mretval\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 284\u001B[0;31m         \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0msum\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mv\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mitem\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mv\u001B[0m \u001B[0;32min\u001B[0m \u001B[0moptimizer_state\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"found_inf_per_device\"\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mvalues\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    285\u001B[0m             \u001B[0mretval\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0moptimizer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstep\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    286\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mretval\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# Start Train\n",
    "best_dice = train(start_epoch, start_iteration, train_loader, test_loader, model, is_amp, optimizer, grad_scaler,\n",
    "                  save_epoch, weight_dir, log_iteration)\n",
    "log_hint(\"Best Dice: {}\".format(str(best_dice)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}